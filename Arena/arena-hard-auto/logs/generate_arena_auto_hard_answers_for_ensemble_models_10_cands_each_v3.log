nohup: ignoring input
{'name': 'config of answer generation for arena-hard-v0.1', 'bench_name': 'arena-hard-v0.1', 'temperature': 0.0, 'max_tokens': 4096, 'num_choices': 10, 'model_list': ['Qwen/Qwen1.5-7B-Chat', 'Nexusflow/Starling-LM-7B-beta', 'meta-llama/Meta-Llama-3-8B-Instruct', 'berkeley-nest/Starling-LM-7B-alpha', 'teknium/OpenHermes-2.5-Mistral-7B', 'mistralai/Mistral-7B-Instruct-v0.2', 'cognitivecomputations/dolphin-2.2.1-mistral-7b', 'microsoft/Phi-3-mini-4k-instruct', 'HuggingFaceH4/zephyr-7b-beta', 'microsoft/Phi-3-small-8k-instruct']}
Output to data/arena-hard-v0.1/model_answer/Qwen1.5-7B-Chat.jsonl
Max Tokens: 4096
Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]Loading checkpoint shards:  25%|██▌       | 1/4 [00:00<00:02,  1.30it/s]Loading checkpoint shards:  50%|█████     | 2/4 [00:01<00:01,  1.35it/s]Loading checkpoint shards:  75%|███████▌  | 3/4 [00:02<00:00,  1.41it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.51it/s]Loading checkpoint shards: 100%|██████████| 4/4 [00:02<00:00,  1.46it/s]
Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.
  0%|          | 0/500 [00:00<?, ?it/s]  0%|          | 1/500 [00:59<8:11:52, 59.14s/it]You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset
  0%|          | 2/500 [01:43<7:00:04, 50.61s/it]  1%|          | 3/500 [03:49<11:43:47, 84.96s/it]  1%|          | 4/500 [05:18<11:56:18, 86.65s/it]  1%|          | 5/500 [07:28<14:02:58, 102.18s/it]  1%|          | 6/500 [09:34<15:06:35, 110.11s/it]  1%|▏         | 7/500 [11:26<15:11:26, 110.93s/it]  2%|▏         | 8/500 [12:56<14:13:29, 104.08s/it]  2%|▏         | 9/500 [14:10<12:54:44, 94.67s/it]   2%|▏         | 10/500 [16:50<15:39:53, 115.09s/it]  2%|▏         | 11/500 [19:08<16:34:32, 122.03s/it]  2%|▏         | 12/500 [20:47<15:34:46, 114.93s/it]  3%|▎         | 13/500 [21:53<13:32:33, 100.11s/it]  3%|▎         | 14/500 [23:41<13:49:35, 102.42s/it]  3%|▎         | 15/500 [24:32<11:44:32, 87.16s/it]   3%|▎         | 16/500 [25:51<11:21:24, 84.47s/it]  3%|▎         | 17/500 [26:17<9:00:18, 67.12s/it]   4%|▎         | 18/500 [28:18<11:07:03, 83.04s/it]  4%|▍         | 19/500 [29:38<10:59:03, 82.21s/it]  4%|▍         | 20/500 [30:46<10:25:07, 78.14s/it]  4%|▍         | 21/500 [31:52<9:53:06, 74.29s/it]   4%|▍         | 22/500 [33:19<10:21:55, 78.06s/it]  5%|▍         | 23/500 [34:30<10:04:35, 76.05s/it]  5%|▍         | 24/500 [35:08<8:33:29, 64.73s/it]   5%|▌         | 25/500 [36:33<9:19:12, 70.64s/it]  5%|▌         | 26/500 [37:28<8:41:23, 66.00s/it]  5%|▌         | 27/500 [39:00<9:42:11, 73.85s/it]  6%|▌         | 28/500 [40:44<10:51:59, 82.88s/it]  6%|▌         | 29/500 [41:47<10:02:59, 76.81s/it]  6%|▌         | 30/500 [42:51<9:32:49, 73.13s/it]   6%|▌         | 31/500 [44:02<9:24:59, 72.28s/it]  6%|▋         | 32/500 [45:25<9:49:19, 75.55s/it]  7%|▋         | 33/500 [47:08<10:53:15, 83.93s/it]  7%|▋         | 34/500 [49:05<12:08:52, 93.85s/it]  7%|▋         | 35/500 [50:24<11:31:54, 89.28s/it]  7%|▋         | 36/500 [51:35<10:47:32, 83.73s/it]  7%|▋         | 37/500 [52:54<10:35:46, 82.39s/it]  8%|▊         | 38/500 [54:34<11:15:09, 87.68s/it]  8%|▊         | 39/500 [55:47<10:39:56, 83.29s/it]  8%|▊         | 40/500 [57:10<10:37:50, 83.20s/it]